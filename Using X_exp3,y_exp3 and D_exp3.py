import numpy as np
import pickle
from sklearn.model_selection import train_test_split

np.random.seed(0)

X_exp = np.load('X_exp3.npy',allow_pickle=True)
y_exp = np.load('y_exp3.npy',allow_pickle=True)
D_exp = np.load('D_exp3.npy',allow_pickle=True)


#family's name
familias_Microsoft=["Backdoor:Win32/Bifrose", "Trojan:Win32/Vundo", "Backdoor:Win32/Cycbot",
                    "BrowserModifier:Win32/Zwangi", "Rogue:Win32/Winwebsec", "Trojan:Win32/Koutodoor",
                    "Backdoor:Win32/Rbot", "Backdoor:Win32/Hupigon", "Trojan:Win32/Startpage"]


X_trein, X_test, y_trein, y_test = train_test_split( X_exp, y_exp, test_size=0.20, random_state=42, stratify=y_exp)
X_train, X_val, y_train, y_val = train_test_split( X_trein, y_trein, test_size=0.15, random_state=42, stratify=y_trein)


print("Amount of samples for Overall Training:",y_trein.shape[0])
print("Amount of samples for Test            :",y_test.shape[0])

print("")
print("Amount of samples for Training     :",y_train.shape[0])
print("Amount of samples for Validation   :",y_val.shape[0])
print("-----------------------------------------------------------------")

print("Sampling Distribution in Overall Training Dataset(X_trein)")
unique, counts = np.unique(y_trein, return_counts=True)
for familia,count in zip(unique,counts):
    print("{:d} - {:31s}: {:5d}".format(familia,familias_Microsoft[familia],count))
print("-----------------------------------------------------------------")

print("Sampling Distribution in Training Dataset(X_train) ")
unique, counts = np.unique(y_train, return_counts=True)
for familia,count in zip(unique,counts):
    print("{:d} - {:31s}: {:5d}".format(familia,familias_Microsoft[familia],count))
print("-----------------------------------------------------------------")
print("Sampling Distribution in Validation Dataset (X_val) ")
unique, counts = np.unique(y_val, return_counts=True)
for familia,count in zip(unique,counts):
    print("{:d} - {:31s}: {:5d}".format(familia,familias_Microsoft[familia],count))
print("-----------------------------------------------------------------")
